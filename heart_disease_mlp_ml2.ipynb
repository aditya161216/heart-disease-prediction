{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02595e5b-ec20-49d3-9207-821e819c4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab95a2-faae-4eae-b303-36aac8a38120",
   "metadata": {},
   "source": [
    "## Clean/preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c3a71d-f6b8-488e-bf43-0215a8c4f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of dataset: (11621, 36)\n",
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Framingham Dataset.csv\")\n",
    "\n",
    "# first we drop columns with more than 50% missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "columns_to_drop = missing_percentage[missing_percentage > 50].index.tolist()\n",
    "cleaned_df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# next we replace numerical columns with the median\n",
    "numerical_columns = ['TOTCHOL', 'GLUCOSE', 'BMI']\n",
    "for col in numerical_columns:\n",
    "    median_value = cleaned_df[col].median()\n",
    "    cleaned_df[col] = cleaned_df[col].fillna(median_value)\n",
    "\n",
    "# we replace binary/categorical columns with the mode\n",
    "categorical_columns = ['BPMEDS']\n",
    "for col in categorical_columns:\n",
    "    mode_value = cleaned_df[col].mode()[0]\n",
    "    cleaned_df[col] = cleaned_df[col].fillna(mode_value)\n",
    "\n",
    "# modify CIGPDAY (number of cigarettes smoked per day)\n",
    "condition = (cleaned_df['CIGPDAY'].isnull()) & (cleaned_df['CURSMOKE'] == 0)\n",
    "cleaned_df.loc[condition, 'CIGPDAY'] = 0\n",
    "\n",
    "median_cigpday = cleaned_df['CIGPDAY'].median()\n",
    "cleaned_df['CIGPDAY'] = cleaned_df['CIGPDAY'].fillna(median_cigpday)\n",
    "\n",
    "\n",
    "# we drop the 'educ' column because it it mostly a socioeconomic feature with low predictive power\n",
    "# won't affect our outcome too much\n",
    "cleaned_df.drop(columns=['educ'], inplace=True)\n",
    "\n",
    "# drop rows with missing HEARTRTE (rather just drop these rows than computing the median, because its only 6 rows)\n",
    "cleaned_df.dropna(subset=['HEARTRTE'], inplace=True)\n",
    "\n",
    "print(f\"Final shape of dataset: {cleaned_df.shape}\")\n",
    "print(f\"Total missing values: {cleaned_df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddec932-29b4-4325-95bf-5b8fba0b625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RANDID  SEX  TOTCHOL  AGE  SYSBP  DIABP  CURSMOKE  CIGPDAY    BMI  \\\n",
      "0    2448    1    195.0   39  106.0   70.0         0      0.0  26.97   \n",
      "1    2448    1    209.0   52  121.0   66.0         0      0.0  25.48   \n",
      "2    6238    2    250.0   46  121.0   81.0         0      0.0  28.73   \n",
      "3    6238    2    260.0   52  105.0   69.5         0      0.0  29.43   \n",
      "4    6238    2    237.0   58  108.0   66.0         0      0.0  28.50   \n",
      "\n",
      "   DIABETES  ...  CVD  HYPERTEN  TIMEAP  TIMEMI  TIMEMIFC  TIMECHD  TIMESTRK  \\\n",
      "0         0  ...    1         0    8766    6438      6438     6438      8766   \n",
      "1         0  ...    1         0    8766    6438      6438     6438      8766   \n",
      "2         0  ...    0         0    8766    8766      8766     8766      8766   \n",
      "3         0  ...    0         0    8766    8766      8766     8766      8766   \n",
      "4         0  ...    0         0    8766    8766      8766     8766      8766   \n",
      "\n",
      "   TIMECVD  TIMEDTH  TIMEHYP  \n",
      "0     6438     8766     8766  \n",
      "1     6438     8766     8766  \n",
      "2     8766     8766     8766  \n",
      "3     8766     8766     8766  \n",
      "4     8766     8766     8766  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e98b5dda-ae6c-4eee-be3c-8615a126fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we drop more columns that give outcome leakage; i.e. columns that give the model future predictions that \n",
    "# we wouldn't realistically have at the time of an actual prediction, such as whether a patient died during the study\n",
    "# also drop additional irrelevant columns\n",
    "target_col = 'ANYCHD'\n",
    "\n",
    "cols_to_drop = [\n",
    "    'RANDID',  # ID column\n",
    "    'TIME', 'PERIOD',  # timing variables\n",
    "    'DEATH', 'STROKE', 'CVD', 'HYPERTEN', 'MI_FCHD', 'HOSPMI', 'ANGINA',  # future outcomes\n",
    "    'TIMEAP', 'TIMEMI', 'TIMEMIFC', 'TIMECHD', 'TIMESTRK', 'TIMECVD', 'TIMEDTH', 'TIMEHYP'  # event times\n",
    "]\n",
    "\n",
    "cleaned_df_final = cleaned_df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de510f2-71d9-4c1d-9c2f-b48fd3fbe02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8134, 17)\n",
      "Test set shape: (3487, 17)\n",
      "Training labels shape: (8134,)\n",
      "Test labels shape: (3487,)\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_df_final.drop(columns=[target_col])\n",
    "y = cleaned_df_final[target_col]\n",
    "\n",
    "# split into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad92c1-c9ff-4281-a055-9ef028e69096",
   "metadata": {},
   "source": [
    "## Build the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef3a51-7cf3-4060-b50b-e5559dd4d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
